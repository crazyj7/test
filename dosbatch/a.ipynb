{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KannadaMNIST analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# \uacbd\uace0 \ubb34\uc2dc (\uc4f8\ub370\uc5c6\ub294 \ub85c\uadf8 \ucd9c\ub825\uae08\uc9c0)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# \uadf8\ub798\ud504 \uad00\ub828 \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "# \ud559\uc2b5\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dropout, MaxPool2D, Flatten, Dense, Softmax\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, K\n",
        "from keras.models import Input, Model\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import gc"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "# import os\n",
        "# from keras import backend as K\n",
        "import warnings\n",
        "from keras.callbacks import Callback\n",
        "from datetime import datetime\n",
        "from pytz import timezone, utc\n",
        "\n",
        "\n",
        "KST = timezone('Asia/Seoul')\n",
        "\n",
        "def dbgprint(msg):\n",
        "    os.system(f'echo \\\"{msg}\\\"')\n",
        "    print(msg) \n",
        "\n",
        "class EpochLogWrite(Callback):\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        tmx = utc.localize(datetime.utcnow()).astimezone(KST).time()\n",
        "        dbgprint('Epoch #{} begins at {}'.format(epoch+1, tmx))\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        tmx = utc.localize(datetime.utcnow()).astimezone(KST).time()\n",
        "        dbgprint('Epoch #{} ends at {}  acc={} val_acc={} '.format(epoch+1, tmx, round(logs['acc'],4), round(logs['val_acc'],4)))\n",
        "\n",
        "\n",
        "SEED=1234\n",
        "dbgprint('hello world. SEED={}'.format(SEED))\n",
        "\n",
        "def seed_All():\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "    config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
        "    tf.set_random_seed(SEED)\n",
        "    sess = tf.Session(graph=tf.get_default_graph(), config=config)\n",
        "    K.set_session(sess)\n",
        "\n",
        "seed_All()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## load data\n",
        "inputdir='../input/Kannada-MNIST/'\n",
        "outputdir='./'\n",
        "datadir='../input/mykannada2/'\n",
        "# datadir='/kaggle/input/mykannada/'\n",
        "\n",
        "\n",
        "dftrain = pd.read_csv(inputdir+'train.csv')\n",
        "dftest = pd.read_csv(inputdir+'test.csv')\n",
        "dfadd = pd.read_csv(inputdir+'Dig-MNIST.csv')\n",
        "dfsub = pd.read_csv(inputdir+'sample_submission.csv')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dftrain = dftrain.append(dfadd, ignore_index=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dftrain.label.value_counts()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dftest.head()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "nptrain = np.asarray(dftrain.iloc[:,1:].values)\n",
        "print('train shape=', nptrain.shape)\n",
        "\n",
        "nptest = np.asarray(dftest.iloc[:,1:].values)\n",
        "print('test shape=', nptest.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "nptrain=nptrain.reshape((-1,28,28,1))\n",
        "print('train shape=', nptrain.shape)\n",
        "nptest=nptest.reshape((-1,28,28,1))\n",
        "print('test shape=', nptest.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def image_show(npdata, labels, cnt, brandom=True):\n",
        "    plt.figure(figsize=(6*cnt, 6))\n",
        "    if brandom:\n",
        "        idx=np.random.randint(0,npdata.shape[0], cnt)\n",
        "    else:\n",
        "        idx=np.arange(cnt)\n",
        "    for i in range(cnt):\n",
        "        plt.subplot(1,cnt, i+1)\n",
        "        plt.title(labels[idx[i]])\n",
        "        imgdata = npdata[idx[i]].squeeze()\n",
        "        plt.imshow(imgdata, cmap='gray')\n",
        "    plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# train \uc774\ubbf8\uc9c0 \ub79c\ub364 \ubcf4\uae30\n",
        "if True:\n",
        "    image_show(nptrain, dftrain.label.values, 6, True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# test \uc774\ubbf8\uc9c0 \ubcf4\uae30.\n",
        "if False:\n",
        "    image_show(nptest, dftest.id, 6, False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dftrain.label.value_counts()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Augument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "datagen1 = ImageDataGenerator(rescale=1./255, shear_range=0.1, zoom_range=0.1, \n",
        "                              horizontal_flip=False, vertical_flip=False,\n",
        "                              width_shift_range=0.1, height_shift_range=0.1, \n",
        "                              rotation_range=15, brightness_range=[0.5, 1.2],\n",
        "                              fill_mode='nearest')\n",
        "datagen2 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "if False:\n",
        "    datagen1.fit(nptrain)\n",
        "    for xbatch, ybatch in datagen1.flow(nptrain, dftrain['label'], batch_size=6, shuffle=True):\n",
        "        image_show(xbatch, ybatch, 6, False)\n",
        "        break\n",
        "\n",
        "\n",
        "if False:\n",
        "    for xbatch, ybatch in datagen2.flow(nptrain, dftrain['label'], batch_size=6, shuffle=False):\n",
        "        image_show(xbatch, ybatch, 6, False)\n",
        "        break"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "datagen3 = ImageDataGenerator(rescale=1./255, shear_range=0.1, zoom_range=0.1,\n",
        "                              horizontal_flip=False, vertical_flip=False,\n",
        "                              width_shift_range=0.1, height_shift_range=0.1,\n",
        "                              rotation_range=15, brightness_range=[0.5, 1.2],\n",
        "                              fill_mode='nearest')\n",
        "samplex = nptrain[0:5]\n",
        "sampley = dftrain['label'][0:5]\n",
        "print('sampley=', sampley)\n",
        "if False:\n",
        "    i=0\n",
        "    for xbatch, ybatch in datagen3.flow(samplex, sampley, batch_size=5, shuffle=False):\n",
        "        print(xbatch.shape, ybatch.shape)\n",
        "        i+=1\n",
        "        image_show(xbatch, ybatch, xbatch.shape[0], False)\n",
        "        if i==3:\n",
        "            break"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# configure"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bDebug=False\n",
        "\n",
        "# running mode\n",
        "# 0: train.\n",
        "# 1: test mode n.\n",
        "# 2: ensemble use all models.\n",
        "RUNMODE_TRAIN_ONE=0\n",
        "RUNMODE_TRAIN_ALL=1\n",
        "RUNMODE_TEST_ONE=2\n",
        "RUNMODE_TEST_ALL=3\n",
        "RUNMODE_TEST_ALL_TTA=4\n",
        "\n",
        "runmode = RUNMODE_TRAIN_ALL\n",
        "\n",
        "\n",
        "epochs = 70"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# !!! curFold 1~6 make 6 models..."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "curFold = 1  # make current fold (1..fold_k)\n",
        "\n",
        "# batch_size=32  # 16, 32, 64  debug.. memory dependent!\n",
        "batch_size=64\n",
        "# K fold\n",
        "fold_k = 4\n",
        "imagesize=28"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if bDebug:\n",
        "    print('Debug Version!!!! ')\n",
        "    print('Fast Fast. Only use 1000 items in train.')\n",
        "    dftrain = dftrain[:1000]\n",
        "    nptrain = nptrain[:1000]\n",
        "    epochs = 10\n",
        "\n",
        "method = 'conv'\n",
        "modelname = 'kannada-v1-'\n",
        "modellist = [modelname+'1-', modelname+'2-', modelname+'3-', \n",
        "             modelname+'4-']\n",
        "#  , modelname+'5-', modelname+'6-'\n",
        "\n",
        "if runmode==RUNMODE_TEST_ONE:\n",
        "    # test model number? 1~6\n",
        "    files = glob.glob(datadir+modelname+str(curFold)+'-*')\n",
        "    if len(files)>0:\n",
        "        mp = max(files, key=os.path.getctime)\n",
        "        modelpath = mp\n",
        "    print('modelpath=', modelpath)\n",
        "\n",
        "\n",
        "skf = StratifiedKFold(fold_k, random_state=SEED)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dftrain.iloc[0:5]['label']"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if runmode==RUNMODE_TRAIN_ONE or runmode==RUNMODE_TRAIN_ALL:\n",
        "    # train\n",
        "   \n",
        "    kk=0\n",
        "    for modelname, (tri, tei) in zip(modellist, skf.split(nptrain, dftrain['label'].values)):\n",
        "        kk+=1\n",
        "        if runmode==RUNMODE_TRAIN_ALL:\n",
        "            curFold = kk\n",
        "        # \uc544\ub798\ub97c \uc8fc\uc11d\ucc98\ub9ac\ud558\uba74 \uc804\uccb4 \ubaa8\ub378 \uc0dd\uc131\uc73c\ub85c \uc624\ub79c \uc2dc\uac04 \uc18c\uc694.\n",
        "        # curFold (1~6) \ud574\ub2f9 \ubaa8\ub378 1\uac1c\ub9cc \uc0dd\uc131.\n",
        "\n",
        "        if runmode==RUNMODE_TRAIN_ONE and kk != curFold:\n",
        "            continue\n",
        "        dbgprint('Make Model={}'.format(kk))\n",
        "\n",
        "        modelpath = outputdir+modelname+method+'-{epoch:03d}-{val_acc:.4f}.ckpt'\n",
        "        print(modelpath)\n",
        "\n",
        "        nptrain_t = nptrain[tri,:]\n",
        "        nptrain_v = nptrain[tei,:]\n",
        "        dbgprint('traincnt={} valcnt={}'.format(len(tri), len(tei)))\n",
        "\n",
        "        dflabel_t = np_utils.to_categorical(dftrain.iloc[tri]['label'])\n",
        "        dflabel_v = np_utils.to_categorical(dftrain.iloc[tei]['label'])\n",
        "\n",
        "        datagen1 = ImageDataGenerator(rescale=1./255, shear_range=0.1, zoom_range=0.1, \n",
        "                                      horizontal_flip=False, vertical_flip=False,\n",
        "                                      width_shift_range=0.1, height_shift_range=0.1, \n",
        "                                      rotation_range=15, brightness_range=[0.5, 1.2],\n",
        "                                      fill_mode='nearest')\n",
        "        datagen2 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "        datagen1.fit(nptrain_t)\n",
        "\n",
        "        train_generator = datagen1.flow(nptrain_t, dflabel_t, batch_size=batch_size, seed=SEED, shuffle=True)\n",
        "        val_generator = datagen1.flow(nptrain_v, dflabel_v, batch_size=batch_size,shuffle=False)\n",
        "\n",
        "        train_generator.reset()\n",
        "        val_generator.reset()\n",
        "\n",
        "        # print(train_generator.class_indices)\n",
        "\n",
        "        ### checkpoint save weights in progress...\n",
        "        cp_callback = ModelCheckpoint(modelpath,  monitor='val_acc', mode='max', save_best_only=True,\n",
        "                                      save_weights_only=False)\n",
        "        es_callback = EarlyStopping(monitor='val_acc',  mode='max', patience=10)\n",
        "\n",
        "        # tensorboard log\n",
        "        if not os.path.exists('log'):\n",
        "            os.mkdir('log')\n",
        "        tensorboard = TensorBoard(log_dir='log/'+str(time.time()))\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(filters = 32, kernel_size = (4,4),padding = 'Same', activation ='relu', \n",
        "                         input_shape = (28,28,1)))\n",
        "        model.add(Conv2D(filters = 32, kernel_size = (4,4),padding = 'Same', activation ='relu'))\n",
        "        model.add(MaxPool2D(pool_size=(2,2)))\n",
        "        model.add(Dropout(rate=0.25))\n",
        "\n",
        "        model.add(Conv2D(filters = 64, kernel_size = (4,4),padding = 'Same', activation ='relu'))\n",
        "        model.add(MaxPool2D(pool_size=(2,2)))\n",
        "        model.add(Dropout(rate=0.25))\n",
        "\n",
        "        model.add(Conv2D(filters = 128, kernel_size = (4,4),padding = 'Same', activation ='relu'))\n",
        "        model.add(Dropout(rate=0.25))\n",
        "\n",
        "        model.add(Conv2D(filters = 256, kernel_size = (4,4),padding = 'Same', activation ='relu'))\n",
        "        model.add(MaxPool2D(pool_size=(2,2)))\n",
        "        model.add(Dropout(rate=0.25))\n",
        "\n",
        "        model.add(Conv2D(filters = 128, kernel_size = (4,4),padding = 'Same', activation ='relu'))\n",
        "        model.add(Dropout(rate=0.25))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(256, activation='relu'))\n",
        "        model.add(Dropout(rate=0.25))\n",
        "        model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "        # model.summary()\n",
        "\n",
        "    #     cblist = [tensorboard, cp_callback, es_callback, EpochLogWrite()]\n",
        "        cblist = [EpochLogWrite(), es_callback, cp_callback]\n",
        "        hist = model.fit_generator( train_generator, initial_epoch=0, epochs = epochs, validation_data=val_generator,\n",
        "                                   callbacks=cblist, steps_per_epoch=len(tri)/batch_size, validation_steps=len(tei)/batch_size)\n",
        "\n",
        "        # model.save(outputdir+'model.h5')   # create last train model file in CWD"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# +\n",
        "\n",
        "if runmode==RUNMODE_TEST_ONE:\n",
        "    print('RUNMODE_TEST_ONE')\n",
        "    model = load_model(modelpath) # load model from modelpath (dataset)\n",
        "    # model.summary()\n",
        "    # test mode\n",
        "    datagen1 = ImageDataGenerator(rescale=1./255)\n",
        "    dflabel = np_utils.to_categorical(dftrain['label'])\n",
        "    print(nptrain.shape)\n",
        "    print(dflabel.shape)\n",
        "    eval_generator = datagen1.flow(nptrain, dflabel, batch_size=batch_size, shuffle=False)\n",
        "    score = model.evaluate_generator(eval_generator, steps=dflabel.shape[0]/batch_size)\n",
        "    # loss and acc\n",
        "    print(score)\n",
        "\n",
        "    # predict\n",
        "    eval_generator.reset()\n",
        "    result = model.predict_generator(eval_generator, steps=dflabel.shape[0]/batch_size)\n",
        "    \n",
        "    predict_result = np.argmax(result, axis=1)\n",
        "\n",
        "    print(predict_result)\n",
        "    print(dftrain['label'].values)\n",
        "    print('match cnt=', np.sum(predict_result==dftrain['label'].values))    "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# +\n",
        "\n",
        "\n",
        "if runmode==RUNMODE_TEST_ONE:\n",
        "    # test mode\n",
        "    datagen1 = ImageDataGenerator(rescale=1./255)\n",
        "    test_generator = datagen1.flow(nptest, batch_size=batch_size, shuffle=False)\n",
        "    result = model.predict_generator(test_generator, steps=len(nptest)/batch_size)\n",
        "    predict_result = np.argmax(result, axis=1)\n",
        "    print(predict_result)\n",
        "\n",
        "    dfsub['label'] = predict_result\n",
        "    dfsub.to_csv('submit.csv', index=False)\n",
        "\n",
        "# +"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if runmode==RUNMODE_TEST_ALL:\n",
        "    print(\"RUNMODE_TEST_ALL\")\n",
        "    datagen1 = ImageDataGenerator(rescale=1. / 255)\n",
        "    test_generator = datagen1.flow(nptest, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    files = glob.glob(datadir+modelname+'*')\n",
        "    resultlist=[]\n",
        "    for modelpath in files:\n",
        "        print('modelpath=', modelpath)\n",
        "        model = load_model(modelpath)\n",
        "\n",
        "        # check model result\n",
        "        test_generator.reset()\n",
        "        result = model.predict_generator(test_generator, steps=len(nptest)/batch_size)\n",
        "        resultlist.append(result)\n",
        "\n",
        "    resultlist = np.asarray(resultlist)\n",
        "    dbgprint(resultlist)\n",
        "    dbgprint(resultlist.shape)\n",
        "\n",
        "    prk = np.mean(resultlist, axis=0)\n",
        "    dbgprint(prk)\n",
        "    dbgprint(prk.shape)\n",
        "\n",
        "    predict_result = np.argmax(prk, axis=1)\n",
        "    dbgprint(predict_result)\n",
        "\n",
        "    dfsub['label'] = predict_result\n",
        "    dfsub.to_csv('submit.csv', index=False)\n",
        "elif runmode==RUNMODE_TEST_ALL_TTA:\n",
        "    print(\"RUNMODE_TEST_ALL_TTA\")\n",
        "    batch_size = 10\n",
        "    ttagen = ImageDataGenerator(rescale=1. / 255, shear_range=0.1, zoom_range=0.1,\n",
        "                                horizontal_flip=False, vertical_flip=False,\n",
        "                                width_shift_range=0.1, height_shift_range=0.1,\n",
        "                                rotation_range=15, brightness_range=[0.5, 1.2],\n",
        "                                fill_mode='nearest')\n",
        "    tta_generator = ttagen.flow(nptest, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    files = glob.glob(datadir + modelname + '*')\n",
        "    resultlist = []\n",
        "    for modelpath in files:\n",
        "        print('modelpath=', modelpath)\n",
        "        model = load_model(modelpath)\n",
        "\n",
        "        tta_generator.reset()\n",
        "        result = model.predict_generator(tta_generator, steps=len(nptest) / batch_size)\n",
        "        resultlist.append(result)\n",
        "\n",
        "        tta_generator.reset()\n",
        "        result = model.predict_generator(tta_generator, steps=len(nptest) / batch_size)\n",
        "        resultlist.append(result)\n",
        "\n",
        "        tta_generator.reset()\n",
        "        result = model.predict_generator(tta_generator, steps=len(nptest) / batch_size)\n",
        "        resultlist.append(result)\n",
        "\n",
        "\n",
        "    resultlist = np.asarray(resultlist)\n",
        "    dbgprint(resultlist)\n",
        "    dbgprint(resultlist.shape)\n",
        "\n",
        "    prk = np.mean(resultlist, axis=0)\n",
        "    dbgprint(prk)\n",
        "    dbgprint(prk.shape)\n",
        "\n",
        "    predict_result = np.argmax(prk, axis=1)\n",
        "    dbgprint(predict_result)\n",
        "\n",
        "    dfsub['label'] = predict_result\n",
        "    dfsub.to_csv('submit.csv', index=False)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}